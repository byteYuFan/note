

# go并发

并发（concurrency）指的是在同一时间内处理多个任务的能力，通常与并行（parallelism）一起被提及。在计算机领域，常见的并发方式是多线程和多进程。

在 Go 语言中，通过 Goroutine 和 Channel 实现并发处理。Goroutine 是一种轻量级线程，可以在单个 OS 线程上并发执行多个 Goroutine，而 Channel 则是一种 Goroutine 之间进行通信的机制。通过使用 Goroutine 和 Channel，可以在 Go 中实现高效的并发处理，而且这种方式比使用传统的多线程方式更容易实现和维护。

在编写并发程序时，需要注意一些问题，如竞态条件、死锁、活锁等。Go 语言提供了一些机制，如 Mutex、RWMutex、WaitGroup 等，来帮助开发者避免这些问题。此外，Go 语言还提供了一些工具，如 go vet、go race detector 等，用于检测和解决并发程序中的问题。



## 1 并行与并发

并发（Concurrency）和并行（Parallelism）都是指同时处理多个任务的能力，但是它们在实现方式和含义上有所不同。

并发是指多个任务交替执行的情况，它是一种对于任务执行时间的安排。当一个任务在等待 I/O 操作完成时，CPU 可以去执行其他任务。在并发情况下，多个任务共享 CPU 和系统资源，通过合理的调度，可以让任务看起来是同时执行的。

与并发不同， 并行是指同时执行多个任务，它是一种对于任务执行方式的安排。在并行情况下，任务不仅能够共享 CPU 和系统资源，还能够使用多个 CPU 或多个处理器同时执行。

在计算机领域，通常使用多线程或多进程实现并发和并行。在多线程的情况下，每个线程都可以独立执行任务，并且可以共享内存和其他资源。在多进程的情况下，每个进程都有自己独立的内存空间和资源，但是它们可以通过 IPC（Inter-process Communication）机制进行通信。

上面的例子提到了并发与并行，这里更精准地阐述一下。

一个基本的事实前提：**一个CPU在一个瞬间只能处理一个任务**。但为什么在我们人类视角，哪怕是单核心计算机也能同时做很多事情，比如同时听音乐和浏览网页，作为整个系统唯一可以完成计算任务的 CPU 是如何保证两个进程“同时进行”的呢？**时间片轮转调度**！

**每个进程会被操作系统分配一个时间片，即每次被 CPU 选中来执行当前进程所用的时间。时间一到，无论进程是否运行结束，操作系统都会强制将 CPU 这个资源转到另一个进程去执行**。为什么要这样做呢？因为只有一个单核 CPU，假如没有这种轮转调度机制，那它该去处理写文档的进程还是该去处理听音乐的进程？无论执行哪个进程，另一个进程肯定是不被执行，程序自然就是无运行的状态。如果 CPU 一会儿处理 word 进程一会儿处理听音乐的进程，起初看起来好像会觉得两个进程都很卡，**但是 CPU 的执行速度已经快到让人们感觉不到这种切换的顿挫感，就真的好像两个进程在“并行运行”**

![](D:\桌面\note\go\images\a478bd68b0f845ec86115e61e5da983d.png)

![](D:\桌面\note\go\images\f9689d356f8747aeab6b50b314a829c4.png)

> 所谓的进程上下文，就是一个进程在执行的时候，CPU的所有寄存器中的值、进程的状态以及堆栈上的内容，当内核需要切换到另一个进程时，它 需要保存当前进程的所有状态，即保存当前进程的进程上下文，以便再次执行该进程时，能够恢复切换时的状态，继续执行。

## 2 进程和线程

操作系统中的线程和进程是实现并发和并行的重要手段。

进程（Process）是指操作系统中正在运行的一个程序实例。每个进程都有自己独立的内存空间和系统资源，包括 CPU 时间、文件、网络连接等。每个进程都由操作系统分配一个唯一的进程 ID（Process ID，简称 PID），用于标识该进程。进程之间通常需要通过 IPC（Inter-process Communication）机制进行通信，这包括共享内存、管道、消息队列等。

线程（Thread）是进程内的一个独立执行流。一个进程可以包含多个线程，这些线程共享进程的内存空间和系统资源。线程是 CPU 调度的基本单位，操作系统可以在多个线程之间切换，从而实现并发和并行。线程的优点是比进程更轻量级，可以更快速地创建和销毁。但是线程之间共享内存，需要考虑同步和互斥等问题，否则可能会导致数据竞争和死锁等问题。

在操作系统中，进程和线程都是用于实现并发和并行的重要手段。选择使用进程还是线程，取决于具体的应用场景和需求。在某些情况下，进程可以更好地实现隔离和安全性，但是会消耗更多的系统资源；在其他情况下，线程可以更好地实现并发和并行，但需要考虑同步和互斥等问题。

**可以将进程看作一个包含了应用进程在运行中需要用到和维护的各种资源的容器。**

**一个线程是一个执行空间，这个空间会被操作系统调度来运行函数中所写的代码。每个进程至少包括一个线程，每个进程的初始线程被称作主线程**

什么是进程

==先给一个定义：进程是一个具有一定独立功能的程序在一个数据集合上依次动态执行的过程。进程是一个正在执行的程序的实例，包括程序计数器、寄存器和程序变量的当前值。==

进程有哪些特征？

1. 进程依赖于程序运行而存在，进程是动态的，程序是静态的；
2. 进程是操作系统进行资源分配和调度的一个独立单位（CPU除外，线程是处理器任务调度和执行的基本单位）；
3. 每个进程拥有独立的地址空间，地址空间包括代码区、数据区和堆栈区，进程之间的地址空间是隔离的，互不影响。

什么是线程？

进程的创建、销毁与切换存在着较大的时空开销，因此人们急需一种轻型的进程技术来减少开销。在80年代，线程的概念开始出现，线程被设计成进程的一个执行路径，同一个进程中的线程共享进程的资源，因此系统对线程的调度所需的成本远远小于进程。

![](D:\桌面\note\go\images\9375f9a10be2461bb699c9f68e7d9c30.png)

![](D:\桌面\note\go\images\58369465841a4cdea8083b6951dff710.jpg)

进程与线程的区别总结：

- 本质区别：进程是操作系统资源分配的基本单位，而线程是处理器任务调度和执行的基本单位。
- 包含关系：一个进程至少有一个线程，线程是进程的一部分，所以线程也被称为轻权进程或者轻量级进程。
- 资源开销：每个进程都有独立的地址空间，进程之间的切换会有较大的开销；线程可以看做轻量级的进程，同一个进程内的线程共享进程的地址空间，每个线程都有自己独立的运行栈和程序计数器，线程之间切换的开销小。
- 影响关系：一个进程崩溃后，在保护模式下其他进程不会被影响，但是一个线程崩溃可能导致整个进程被操作系统杀掉，所以多进程要比多线程健壮。

进程与线程的一个简陋模型用图表示的话，是这样的：

![]()![9aa019f39869448fbfe93e93bfe785bb](D:\桌面\note\go\images\9aa019f39869448fbfe93e93bfe785bb.png)

理论过于抽象难解，下面还是用大家喜闻乐见的现实中的例子去类比，没错还是工厂的例子：

![](D:\桌面\note\go\images\ad66372881fc4bcf8e6397e4c112faba.png)

在计算机这个大工厂中，进程被比作一个车间，**为生产活动提供了设计图、场地、生产线（线程）等生产要素，而线程是这个车间中的一条条生产线**。生产线本身会有一个操作台，具体的零件在这里被生产。生产线必须由工人操作才能动起来，当工人来到一个生产线旁并启动它之前，必须查阅生产线的生产记录以便弄清楚这个生产线的零件加工到哪种程度了，然后才能准确地接续生产，当工人停止生产线前也必须记录这次的生产进度以备下次读取，==这些进度信息可以理解为上下文，读取和记录生产进度的过程称为上下文切换==。

**一个工人可以在多条生产线间穿梭操作，就像CPU在不同线程间切换一样，这个动作被称为并发**，与之对应的，多个工人操作多条生产线同时生产，称为并行。如果生产线不需要太多原料输入就能生产，那这种生产任务被称作==CPU密集型==，反之如果生产线大部分时间在等待原料的输入，那这种任务被称为==IO密集型==。显然，前者最好一条生产线由一个工人专管效率更高，**而后一种任务，一个人在原料输入的间隙去操作其他生产线，无疑能提高工人利用率。**

## 3 线程如何共享进程资源

这一节选自 [知乎-码农的荒岛求生](https://www.zhihu.com/question/519893352)，文章非常精彩。

我将其总结如下：

这个问题的答案其实很简单，就一句话：**同一个进程内的线程共享其所属进程的[地址空间](https://www.zhihu.com/search?q=地址空间&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2375191174})，因此地址空间里有啥就共享啥。**

面试官很可能继续问你能不能说具体点呢？啊哈，这可难不倒你，接下来我会用一个长篇来回答这个问题。

### 3.1 逆向思考

[查理芒格](https://www.zhihu.com/search?q=查理芒格&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2375191174})经常说这样一句话：“反过来想，总是反过来想”，如果你对线程之间共享了哪些进程资源这个问题想不清楚的话那么也可以反过来思考，那就是**有哪些资源是线程私有的**。

### 线程私有资源

线程运行的本质其实就是函数的执行，函数的执行总会有一个源头，这个源头就是所谓的入口函数，CPU从入口函数开始执行从而形成一个[执行流](https://www.zhihu.com/search?q=执行流&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2375191174})，只不过我们人为的给执行流起一个名字，这个名字就叫线程。

既然线程运行的本质就是函数的执行，那么函数执行都有哪些信息呢？

在《[函数运行时在内存中是什么样子？](https://zhuanlan.zhihu.com/p/339866296)》这篇文章中我们说过，函数运行时的信息保存在[栈帧](https://www.zhihu.com/search?q=栈帧&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2375191174})中，栈帧中保存了函数的返回值、调用其它函数的参数、该函数使用的局部变量以及该函数使用的寄存器信息，如图所示，假设函数A[调用函数](https://www.zhihu.com/search?q=调用函数&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2375191174})B：

![](D:\桌面\note\go\images\v2-7141d66bad78801b3249c22fd75c6acd_720w.webp)

此外，CPU执行指令的信息保存在一个叫做[程序计数器](https://www.zhihu.com/search?q=程序计数器&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2375191174})的寄存器中，通过这个寄存器我们就知道接下来要执行哪一条指令。由于操作系统随时可以暂停线程的运行，因此我们保存以及恢复程序计数器中的值就能知道线程是从哪里暂停的以及该从哪里继续运行了。

由于线程运行的本质就是函数运行，函数运行时信息是保存在栈帧中的，因此每个线程都有自己独立的、私有的栈区。

![](D:\桌面\note\go\images\v2-7a23d1af682e4630ddec7f31ac4f6ead_720w.webp)

同时函数运行时需要额外的寄存器来保存一些信息，像部分局部变量之类，这些寄存器也是线程私有的，**一个线程不可能访问到另一个线程的这类寄存器信息**。

从上面的讨论中我们知道，到目前为止，所属线程的[栈区](https://www.zhihu.com/search?q=栈区&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2375191174})、程序计数器、栈指针以及函数运行使用的寄存器是线程私有的。

以上这些信息有一个统一的名字，就是**[线程上下文](https://www.zhihu.com/search?q=线程上下文&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2375191174})**，thread context。

我们也说过操作系统调度线程需要随时中断线程的运行并且需要线程被暂停后可以继续运行，操作系统之所以能实现这一点，依靠的就是线程上下文信息。

现在你应该知道哪些是线程私有的了吧。

除此之外，剩下的都是线程间共享资源。

那么剩下的还有什么呢？还有图中的这些。

![](D:\桌面\note\go\images\v2-8f47a0f3a4c168c8dab0abe667b56dea_720w.webp)

这其实就是[进程地址空间](https://www.zhihu.com/search?q=进程地址空间&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2375191174})的样子，也就是说线程共享进程地址空间中除线程上下文信息中的所有内容，意思就是说线程可以**直接读取**这些内容。

接下来我们分别来看一下这些区域。

### 3.2 代码区

进程地址空间中的代码区，这里保存的是什么呢？从名字中有的同学可能已经猜到了，没错，这里保存的就是我们写的代码，**更准确的是编译后的[可执行机器指令](https://www.zhihu.com/search?q=可执行机器指令&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2375191174})**。

那么这些机器指令又是从哪里来的呢？答案是从[可执行文件](https://www.zhihu.com/search?q=可执行文件&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2375191174})中加载到内存的，可执行程序中的代码区就是用来初始化进程地址空间中的代码区的。

![](D:\桌面\note\go\images\v2-a2cc0692f67f61b403b7b555b9926fb6_720w.webp)

线程之间共享代码区，**这就意味着程序中的任何一个函数都可以放到线程中去执行，不存在某个函数只能被特定线程执行的情况**。

### 3.3 堆区

堆区是程序员比较熟悉的，我们在C/C++中用[malloc](https://www.zhihu.com/search?q=malloc&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2375191174})或者new出来的数据就存放在这个区域，很显然，**只要知道变量的地址，也就是指针，任何一个线程都可以访问指针指向的数据**，因此堆区也是线程共享的属于进程的资源。

![](D:\桌面\note\go\images\v2-df4dab7c21014f297e1871ffc90a91c0_720w.webp)

### 3.4 栈区

唉，等等！刚不是说栈区是线程私有资源吗，怎么这会儿又说起栈区了？

确实，从线程这个抽象的概念上来说，栈区是线程私有的，然而从实际的实现上看，**栈区属于线程私有这一规则并没有严格遵守**，这句话是什么意思？

通常来说，注意这里的用词是**通常**，通常来说栈区是线程私有，既然有通常就有不通常的时候。

不通常是因为不像进程地址空间之间的严格隔离，线程的栈区没有严格的隔离机制来保护，因此如果一个线程能拿到来自另一个线程栈帧上的指针，**那么该线程就可以改变另一个线程的栈区**，也就是说这些线程可以任意修改本属于另一个[线程栈区](https://www.zhihu.com/search?q=线程栈区&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2375191174})中的变量。

![](D:\桌面\note\go\images\v2-cff6629097187dca89f02fdd183b161c_720w.webp)

这从某种程度上给了程序员极大的便利，但同时，这也会导致极其难以排查到的bug。

试想一下你的程序运行的好好的，结果某个时刻突然出问题，定位到出问题代码行后根本就排查不到原因，你当然是排查不到问题原因的，因为你的程序本来就没有任何问题，是别人的问题导致你的函数栈帧数据被写坏从而产生bug，这样的问题通常很难排查到原因，需要对整体的项目代码非常熟悉，常用的一些debug工具这时可能已经没有多大作用了。

说了这么多，那么同学可能会问，一个线程是怎样修改本属于其它线程的数据呢？

接下来我们用一个代码示例讲解一下。

### 3.5 文件

最后，如果程序在运行过程中打开了一些文件，那么进程地址空间中还保存有打开的文件信息，进程打开的文件也可以被所有的线程使用，这也属于线程间的共享资源。关于文件IO操作，你可以参考《[读取文件时，程序经历了什么？](https://zhuanlan.zhihu.com/p/260375849)》

![](D:\桌面\note\go\images\v2-130f269f2dc378a022720a4a4478006d_720w.webp)

### 3.6 One More Thing：TLS

本文就这些了吗？

实际上本篇开头关于线程[私有数据](https://www.zhihu.com/search?q=私有数据&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2375191174})还有一个项没有详细讲解，因为再讲下去本篇就撑爆了，实际上本篇讲解的已经足够用了，剩下的这一点仅仅作为补充。

关于线程私有数据还有一项技术，那就是[线程局部存储](https://www.zhihu.com/search?q=线程局部存储&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2375191174})，Thread Local Storage，TLS。

这是什么意思呢？

其实从名字上也可以看出，所谓线程局部存储，是指存放在该区域中的变量有两个含义：

- 存放在该区域中的变量是全局变量，所有线程都可以访问
- 虽然看上去所有线程访问的都是同一个变量，但该全局变量独属于一个线程，一个线程对此变量的修改对其他线程不可见。

说了这么多还是没懂有没有？没关系，接下来看完这两段代码还不懂你来打我。

我们先来看第一段代码，不用担心，这段代码非常非常的简单：

```cpp
int a = 1; // 全局变量

void print_a() {
    cout<<a<<endl;
}

void run() {
    ++a;
    print_a();
}

void main() {
    thread t1(run);
    t1.join();

    thread t2(run);
    t2.join();
}

```

怎么样，这段代码足够简单吧，上述代码是用C++11写的，我来讲解下这段代码是什么意思。

- 首先我们创建了一个全局变量a，初始值为1
- 其次我们创建了两个线程，每个线程对变量a加1
- 线程的join函数表示该线程运行完毕后才继续运行接下来的代码

那么这段代码的运行起来会打印什么呢？

全局变量a的初始值为1，第一个线程加1后a变为2，因此会打印2；第二个线程再次加1后a变为3，因此会打印3，让我们来看一下运行结果：

```shell
2
3
```

看来我们分析的没错，全局变量在两个线程分别加1后最终变为3。

接下来我们对变量a的定义稍作修改，其它代码不做改动：

```c++
__thread int a = 1; // 线程局部存储
```

我们看到全局变量a前面加了一个__thread关键词用来修饰，也就是说我们告诉编译器把变量a放在线程局部存储中，那这会对程序带来哪些改变呢？

简单运行一下就知道了：

```shell
2
2
```

和你想的一样吗，有的同学可能会大吃一惊，为什么我们明明对变量a加了两次，但第二次运行为什么还是打印2而不是3呢？

想一想这是为什么。

原来，这就是线程局部存储的作用所在，线程t1对变量a的修改不会影响到线程t2，线程t1在将变量a加到1后变为2，但对于线程t2来说此时变量a依然是1，因此加1后依然是2。

因此，**线程局部存储可以让你使用一个独属于线程的全局变量**。也就是说，虽然该变量可以被所有线程访问，但该变量在每个线程中都有一个副本，一个线程对改变量的修改不会影响到其它线程。

![](D:\桌面\note\go\images\v2-5d9e3cba6a846e603f9ccda1a7cae42f_720w.webp)

怎么样，没想到教科书上一句简单的“线程共享进程资源”背后竟然会有这么多的知识点吧，**教科书上的知识确实枯燥，但，并不简单**。

## 4 go的并发(goroutine)

**操作系统会在物理处理器上调度线程来运行，而go语言的运行时会在逻辑处理器上调度goroutine来运行。每个逻辑处理器都分别绑定到单个操作系统线程。**

Go 语言的并发调度是由 Go 运行时系统负责管理的。Go 运行时系统会在程序启动时创建一个称为 G 的 Goroutine 结构体，Goroutine 是 Go 语言中的一种轻量级线程，每个 Goroutine 都可以在单个 OS 线程上并发执行。

当一个 Goroutine 需要等待 I/O 操作或者其他阻塞操作完成时，Go 运行时系统会将其阻塞，并在此期间执行其他 Goroutine。当 I/O 操作或者其他阻塞操作完成时，Go 运行时系统会重新调度该 Goroutine，让其继续执行。

Go 运行时系统使用了一些高效的调度算法，以保证 Goroutine 的高效执行。其中最重要的算法是 GMP（Goroutine, Memory, Processor），它能够将多个 Goroutine 映射到少量的 OS 线程上执行。在 GMP 模型下，每个 OS 线程都有一个 Goroutine 队列和一个调度器，负责调度和执行 Goroutine。

Go 运行时系统还提供了一些原语和 API，例如 Channel 和 sync 包等，用于在 Goroutine 之间进行通信和同步。通过使用这些原语和 API，可以更加方便地编写并发程序，避免常见的并发问题，例如竞争条件、死锁和饥饿等。

总的来说，Go 语言的并发调度是由 Go 运行时系统负责管理的，采用了高效的调度算法和原语，以保证 Goroutine 的高效执行。这使得编写高效的并发程序变得更加容易和方便。

**Go 语言的逻辑处理器（Logical Processor）是指一种虚拟的 CPU，用于并发执行 Goroutine**。==每个逻辑处理器都可以与一个 OS 线程绑定，多个逻辑处理器可以同时运行在多个 OS 线程上，以实现并发和并行执行。==

**Go 语言的逻辑处理器由 Go 运行时系统管理和调度，可以使用 runtime 包中的 GOMAXPROCS 函数来设置逻辑处理器的数量**。GOMAXPROCS 函数默认值为 CPU 核心数，即系统可以同时执行的 Goroutine 数量。

在运行时，每个逻辑处理器都有一个 Goroutine 队列，用于存储待执行的 Goroutine。当一个 Goroutine 需要执行时，Go 运行时系统会将其放入逻辑处理器对应的 Goroutine 队列中，并通知所在的 OS 线程来执行该 Goroutine。当 Goroutine 遇到 I/O 操作或者其他阻塞操作时，Go 运行时系统会将其从逻辑处理器的 Goroutine 队列中移除，并将该逻辑处理器分配给其他 Goroutine 执行。

在 Go 语言中，使用多个逻辑处理器可以提高程序的并发和并行性能，特别是在多核 CPU 上。但是需要注意，**过多的逻辑处理器数量可能会导致调度器性能下降**，造成性能问题。因此，需要根据具体的应用场景和需求来设置逻辑处理器的数量。

总的来说，Go 语言的逻辑处理器是一种==虚拟的 CPU==，用于并发执行 Goroutine，由 Go 运行时系统管理和调度，可以通过 runtime 包中的 GOMAXPROCS 函数来设置数量。合理设置逻辑处理器数量可以提高程序的并发和并行性能。

这篇文章写的非常好：[调度机制](http://segmentfault.com/a/1190000042523723)

### 4.1 什么是goroutine

在go语言中，**每一个并发的执行单元叫作一个goroutine**，与并发相对的是串行，即代码按照顺序一行一行执行，goroutine 给 go 语言提供了并发编程的能力。

当一个程序启动时，其主函数在一个单独的goroutine中运行，我们叫它main goroutine，新的goroutine会用go语句来创建。在语法上，go语句是一个普通的函数或方法调用前加上关键字go，go语句会使其语句中的函数在一个新创建的goroutine 中运行。

```go
f()    // call f(); wait for it to return
go f() // create a new goroutine that calls f(); don't wait
```

在 Go 语言中通过协程实现并发编程非常简单：我们可以在一个处理进程中通过关键字 go 启用多个协程，然后在不同的协程中完成不同的子任务。

**Goroutine 可以看作对 thread 加的一层抽象，它是用户态的，更轻量。因为有了这层抽象，Gopher 不会直接面对 thread。操作系统却相反，是看不到 goroutine 存在的，安心地执行线程就可以了，线程才是它调度的基本单位。**

### **4.2 Goroutine 和 thread 有什么区别？**

#### **1 内存占用**

创建一个 goroutine 的栈内存消耗为 2 KB，实际运行过程中，如果栈空间不够用，会**自动进行扩容**。创建一个 thread 则需要消耗 1 MB 栈内存。

对于一个用 Go 构建的 HTTP Server 而言，对到来的每个请求，创建一个 goroutine 用来处理是**非常轻松**的一件事。而如果用一个使用线程作为并发原语的语言构建的服务，例如 Java 来说，每个请求对应一个线程则太浪费资源了，很快就会出 OOM 错误（Out Of Mermory Error）。

#### **2 创建和销毀**

​		Thread 创建和销毀都会有巨大的消耗，因为要和操作系统打交道，是内核级的，通常解决的办法就是线程池。而 **goroutine 因为是由 Go runtime 负责管理的，创建和销毁的消耗非常小，是==用户级==。**

#### **3 切换**

​		当 threads 切换时，需要保存各种寄存器，以便将来恢复：包括所有的寄存器，16个通用寄存器、程序计数器、栈指针、段寄存器、16个XMM寄存器、FP协处理器、16个 AVX寄存器、所有的MSR等等。

goroutine的保存和恢复只需要三个寄存器：程序计数器、栈指针和DX寄存器，也不需要陷入操作系统内核层。

一般而言，线程切换会消耗 1000-1500 纳秒，**Goroutine 的切换约为 200 ns**，相比之下goroutines 切换成本比 threads 要小得多。

### 4.3 线程的并发模型

线程是操作系统内核的最小调度单元，我们上面所说的goroutine 也是基于线程，根据用户线程与内核线程的对应关系，分为以下几种并发模型：

#### 1 用户级线程模型

用户线程与内核线程是多对一（N : 1）的映射模型，即一个进程中所有创建的线程都只和同一个内核线程在运行时动态绑定，python实现的协程库gevent就都属于这种方式。

这些线程的创建、销毁以及多线程之间的协调等操作都是由用户自己的线程库来负责而无须借助系统调用来实现，这种实现方式相比内核级线程可以做的很轻量级，对系统资源的消耗会小很多，因此可以创建的线程数量与上下文切换所花费的代价也会小得多。但该模型有个原罪：并不能做到真正意义上的并发，假设在某个用户进程上的某个用户线程因为一个阻塞调用（比如 I/O 阻塞）而被 CPU 给中断（抢占式调度）了，那么该进程内的所有线程都被阻塞，整个进程被挂起。

<img src="D:\桌面\note\go\images\1348734214-633505c17d2ed.png" style="zoom:67%;" />

#### 2  内核级线程模型

用户线程与内核线程 KSE 是一对一（1 : 1）的映射模型，也就是每一个用户线程绑定一个实际的内核线程，而线程的调度则完全交付给操作系统内核去做，Java 的线程便是基于此实现的。

这种模型的优势是实现简单，直接借助操作系统内核的线程以及调度器，所以 CPU 可以快速切换调度线程，于是多个线程可以同时运行，因此相较于用户级线程模型它真正做到了并行处理；但它的劣势是，由于直接借助了操作系统内核来创建、销毁和以及多个线程之间的上下文切换和调度，因此资源成本大幅上涨，且对性能影响很大。

![](D:\桌面\note\go\images\3874557468-633505f91745b_fix732.png)

#### 3 两级线程模型

用户线程与内核是多对多（N : M）的映射模型，该模型对于前面两种模型扬长避短：首先，区别于用户级线程模型，两级线程模型中的一个进程可以与多个内核线程关联，也就是说一个进程内的多个线程可以分别绑定一个自己的 KSE，这点和内核级线程模型相似；其次，又区别于内核级线程模型，它的进程里的线程并不与 KSE 唯一绑定，而是可以多个用户线程映射到同一个 KSE，当某个 KSE 因为其绑定的线程的阻塞操作被内核调度出 CPU 时，其关联的进程中其余用户线程可以重新与其他 KSE 绑定运行。

这种模型实现比较复杂，Go 语言中的 runtime 调度器就是采用的这种实现方案，实现了 Goroutine 与 KSE 之间的动态关联，不过 Go 语言的实现更加高级和优雅；该模型为何被称为两级？即用户调度器实现用户线程到 KSE 的『调度』，内核调度器实现 KSE 到 CPU 上的『调度』。

![](D:\桌面\note\go\images\692455274-6335060b2d562_fix732.png)

### 5 Go调度器的作用

提到“调度”，我们首先想到的就是操作系统对进程、线程的调度。操作系统调度器会将系统中的多个线程按照一定算法调度到物理CPU上去运行。

![](D:\桌面\note\go\images\3339341281-632a8b0d6e697_fix732.png)

这种传统支持并发的方式有诸多不足：
一个thread的代价已经比进程小了很多了，但我们依然不能大量创建thread，因为除了每个thread占用的资源不小之外，线程开得越多操作系统调度切换的代价也就更大；

一个Go程序对于操作系统来说只是一个用户层程序，它的眼中只有thread，它甚至不知道Goroutine的存在。将这些goroutines按照一定算法放到“CPU”上执行的程序就称为goroutine调度器或goroutine scheduler。在操作系统层面，Thread竞争的“CPU”资源是真实的物理CPU，但在Go程序层面，各个Goroutine要竞争的”CPU”资源是操作系统线程。

说到这里goroutine scheduler的任务就明确了：
**goroutine调度器通过使用与CPU数量相等的线程减少线程频繁切换的内存开销，同时在每一个线程上执行额外开销更低的 Goroutine 来降低操作系统和硬件的负载。**

#### Workflow

```shell
                           +-------------------- sysmon ---------------//------+ 
                            |                                                   |
                            |                                                   |
               +---+      +---+-------+                   +--------+          +---+---+
go func() ---> | G | ---> | P | local | <=== balance ===> | global | <--//--- | P | M |
               +---+      +---+-------+                   +--------+          +---+---+
                            |                                 |                 | 
                            |      +---+                      |                 |
                            +----> | M | <--- findrunnable ---+--- steal <--//--+
                                   +---+ 
                                     |
                                   mstart
                                     |
              +--- execute <----- schedule 
              |                      |   
              |                      |
              +--> G.fn --> goexit --+ 


              1. go func() 语句创建G。
              2. 将G放入P的本地队列（或者平衡到全局队列）。
              3. 唤醒或新建M来执行任务。
              4. 进入调度循环
              5. 尽力获取可执行的G，并执行
              6. 清理现场并且重新进入调度循环
```

### 6 Go调度器模型与演化过程

2012年3月28日，Go 1.0正式发布。在这个版本中，每个goroutine对应于runtime中的一个抽象结构：G，而os thread则被抽象为一个结构：M。

#### 1 G-M模型

![](D:\桌面\note\go\images\4261573264-632ab85d19c4e_fix732.png)

这个结构虽然简单，但是却存在着许多问题：

M想要执行、放回G都必须访问全局G队列，并且M有多个，即多线程访问同一资源需要加锁进行保证互斥/同步，所以全局G队列是有互斥锁进行保护的。

这个结构虽然简单，但是却存在着许多问题：
1、所有goroutine相关操作，比如：创建、重新调度等都要上锁；
2、M转移G会造成延迟和额外的系统负载。比如当G中包含创建新协程的时候，M创建了G1，为了继续执行G，需要把G1交给M1执行，也造成了很差的局部性，因为G1和G是相关的，最好放在M上执行，而不是其他M1。
3、系统调用(CPU在M之间的切换)导致频繁的线程阻塞和取消阻塞操作增加了系统开销。

#### 2 G-P-M模型

在Go 1.1中实现了G-P-M调度模型和work stealing算法，这个模型一直沿用至今：

![](D:\桌面\note\go\images\2193568693-632aba6cab907_fix732.png)

在新调度器中，除了M(thread)和G(goroutine)，又引进了P(Processor)。P是一个“逻辑Proccessor”，每个G要想真正运行起来，首先需要被分配一个P（进入到P的本地队列中），对于G来说，P就是运行它的“CPU”，可以说：G的眼里只有P。但从Go scheduler视角来看，真正的“CPU”是M，只有将P和M绑定才能让P的runq中G得以真实运行起来。

#### 3 抢占式调度

G-P-M模型的实现算是Go scheduler的一大进步，但Scheduler仍然有一个头疼的问题，那就是不支持抢占式调度，导致一旦某个G中出现死循环或永久循环的代码逻辑，那么G将永久占用分配给它的P和M，位于同一个P中的其他G将得不到调度，出现“饿死”的情况。更为严重的是，当只有一个P时(GOMAXPROCS=1)时，整个Go程序中的其他G都将“饿死”。

这个抢占式调度的原理则是在每个函数或方法的入口，加上一段额外的代码，让runtime有机会检查是否需要执行抢占调度。

### 7 G-P-M模型的深入理解

```tex
1、全局队列：存放等待运行的G;

2、P的本地队列：同全局队列类似，存放的也是等待运行的G，存储数量不超过256个;

3、G：Groutine协程，调度系统的最基本单位，拥有运行函数的指针、栈、上下文;

4、P：Processor，调度逻辑处理器，拥有各种G对象队列、链表、一些cache和状态,P的数量决定了系统内最大可并行的G的数量;

所有的P都在程序启动时创建，并保存在数组中，默认等于CUP核数，最多有GOMAXPROCS(可配置)个；

5、M：代表实际工作的执行者，对应到操作系统级别的线程，每个M就像一个勤劳的工作者，从各种队列中找到可运行的G；

```

![](D:\桌面\note\go\images\3594915688-632abb739ad7d_fix732.png)

地鼠用小车运着一堆待加工的砖，M就可以看作图中的地鼠，P就是小车，G就是小车里装的砖。

**goroutine 的创建与调度循环是一个生产-消费流程，整个 go 程序的运行就是在不断地执行 goroutine 的生产与消费流程。**

#### 1 调度器的设计策略

##### 1.1 复用线程

避免频繁的创建、销毁线程，而是对线程的复用。
1）work stealing机制
当本线程无可运行的G时，尝试从其他线程绑定的P偷取G，而不是销毁线程。

2）hand off机制
当本线程因为G进行系统调用阻塞时，线程释放绑定的P，把P转移给其他空闲的线程执行。

##### 1.2 利用并行

GOMAXPROCS设置P的数量，最多有GOMAXPROCS个线程分布在多个CPU上同时运行。

##### 1.3 抢占

Go 程序启动时，运行时会去启动一个名为 sysmon 的 M，会定时向长时间（>=10MS）运行的 G 任务发出抢占调度，防止其他goroutine被饿死。

#### 2 goroutine的调度流程

![](D:\桌面\note\go\images\31410863-632ac5ca1144c_fix732.png)

、我们通过 go func()来创建一个goroutine；

2、有两个存储G的队列，一个是局部调度器P的本地队列、一个是全局G队列。新创建的G会先保存在P的本地队列中，如果P的本地队列已经满了就会保存在全局的队列中；

3、G只能运行在M中，一个M必须持有一个P，M与P是1:1的关系；

4、一个M调度G执行的过程是一个循环机制，M会从P的本地队列弹出一个可执行状态的G来执行，如果P的本地队列为空，就会去看全局队列，全局也没有就会从其他的MP组合偷取一个可执行的G来执行，如果其他队列也获取不到M就会自旋；

5、如果 G 被阻塞在某个 channel 操作或网络 I/O 操作上时，G 会被放置到某个等待(wait)队列中，而 M 会尝试运行 P 的下一个可运行的 G。如果这个时候 P 没有可运行的 G 供 M运行，那么 M 将解绑 P，并进入挂起状态。

当 I/O 操作完成或 channel 操作完成，在等待队列中的 G 会被唤醒，标记为可运行(runnable)，并被放入到某 P 的队列中，绑定一个 M 后继续执行。

6、如果 G 被阻塞在某个系统调用(system call)上，那么不光 G 会阻塞，执行这个 G 的 M也会解绑 P，与 G 一起进入挂起状态。如果此时有空闲的 M，那么 P 就会和它绑定，并继续执行其他 G;如果没有空闲的 M，但仍然有其他 G 要去执行，那么 Go 运行时就会创建一个新 M(线程)。

当M系统调用结束时候，这个G会尝试获取一个空闲的P执行，并放入到这个P的本地队列。如果获取不到P，那么这个线程M变成休眠状态，加入到空闲线程中，然后这个G会被放入全局队列中。

7、当一个新的goroutine创建或者有多个goroutine进入等待运行状态时，会先判断是否有自旋的M，有则使用自旋的M，当没有自旋的M，但m空闲队列中有空闲的M则会唤醒M，否则会创建一个新的M。

#### 3 调度器的生命周期

![](D:\桌面\note\go\images\2242803647-632ac85ac8be7_fix732.png)

特殊的M0和G0
**M0**
M0是启动程序后的编号为0的主线程，M0负责执行初始化操作和启动第一个G，还在整个运行期专门负责做特定的事情——系统监控(sysmon)。

**G0**
G0是每次启动一个M都会第一个创建的gourtine，G0仅用于负责调度的G，G0不指向任何可执行的函数, 每个M都会有一个自己的G0。在调度或系统调用时会使用G0的栈空间, 全局变量的G0是M0的G0。

调度器的运行流程如图所示：

1. runtime创建最初的线程m0和goroutine g0，并把2者关联。
2. 调度器初始化：初始化m0、栈、垃圾回收，以及创建和初始化由GOMAXPROCS个P构成的P列表。
3. runtime中也有1个main函数——runtime.main，代码经过编译后，runtime.main会调用main.main，程序启动时会为runtime.main创建goroutine，称它为main goroutine吧，然后把main goroutine加入到P的本地队列。
4. 启动m0，m0已经绑定了P，会从P的本地队列获取G，获取到main goroutine。
5. G拥有栈，M根据G中的栈信息和调度信息设置运行环境
6. M运行G
7. G退出，再次回到M获取可运行的G，这样重复下去，直到main.main退出，runtime.main执行Defer和Panic处理，或调用runtime.exit退出程序。

调度器的生命周期几乎占满了一个Go程序的一生，runtime.main的goroutine执行之前都是为调度器做准备工作，runtime.main的goroutine运行，才是调度器的真正开始，直到runtime.main结束而结束。

**Go调度器的本质是把大量的goroutine任务分配到少量线程上运行，利用多核并行，实现更强大的并**发。