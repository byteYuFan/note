# 谈谈字典

**Redis是如何支持基于key的快速访问的**

一谈到redis，马上能想到的就是块，那么Redis之所以块，一方面是因为Redis的所有操作都是在 内存中完成的，内存操作本身就快，另一方面就要归功于它的数据结构了，高效的数据结构是Redis块的基石。

## 1. 全局哈希

为了实现基于Key的快速访问，Redis采用了哈希表作为最底层的数据存储结构，如果你了解Java中的HashMap，那么理解Redis的哈希表则应该非常容易，实际上也就是**数组+链表**的结构，这样一来，我们就可以在O(1)的时间复杂度下快速的查找出所需的Key，并且无论是多少Key都不受影响。

我采用极客时间上的一张图来在为你展示Redis的存储结构。

<img src="D:\桌面\note\redis\redis设计与实现\images\全局hash.webp" style="zoom: 33%;" />

在本章中，我们主要以redis-5.0版本的代码介绍，最后会稍微介绍以下目前最新版本的dict实现方式。

我先用一张图片来为大家展示一下，稍后会详细的分析每一个字段。

<img src="D:\桌面\note\redis\redis设计与实现\images\hash表结构.png" style="zoom:60%;" />

上面这张图就是dict的内部关联图了，下面我们从内向外逐步的解析：

### 1.1. 哈希节点

```c
typedef struct dictEntry {
    void *key;
    union {
        void *val;
        uint64_t u64;
        int64_t s64;
        double d;
    } v;
    struct dictEntry *next;
} dictEntry;

```

那么为了实现链式哈希， Redis 在每个 dictEntry 的结构设计中，除了包含指向键和值的指针，还包含了指向下一个哈希项的指针。如下面的代码所示，dictEntry 结构体中包含了指向另一个 dictEntry 结构的指针 *next，这就是用来实现链式哈希的。

除了用于实现链式哈希的指针外，这里还有一个值得注意的地方，就是在 dictEntry 结构体中，键值对的值是由一个==联合体 v==定义的。这个联合体 v 中包含了指向实际值的指针 *val，还包含了无符号的 64 位整数、有符号的 64 位整数，以及 double 类的值。我之所以要提醒你注意这里，其实是为了说明，这种实现方法是一种节省内存的开发小技巧，非常值得学习。因为当值为整数或双精度浮点数时，由于其本身就是 64 位，就可以不用指针指向了，而是可以直接存在键值对的结构体中，这样就避免了再用一个指针，从而节省了内存空间。

那么，这种方式是如何解决链式冲突的呢，我们继续以一张图来描述。

![](D:\桌面\note\redis\redis设计与实现\images\链式哈希.webp)

在看看源代码：

```c
dictEntry *dictAddRaw(dict *d, void *key, dictEntry **existing)
{
    long index;
    dictEntry *entry;
    dictht *ht;
    if ((index = _dictKeyIndex(d, key, dictHashKey(d,key), existing)) == -1)
        return NULL;
  	...
    ht = dictIsRehashing(d) ? &d->ht[1] : &d->ht[0];
    entry = zmalloc(sizeof(*entry));
    entry->next = ht->table[index];
    ht->table[index] = entry;
    ht->used++;
	...
    return entry;
}

```

我省略了里面对解决哈希冲突无用的代码，这样能确保我们可以更好的理解这些代码，我大概向大家描述一下这段代码的意图：

> 首先，他去字典中找有没有key这个键，没有的话返回，有的话返回节点的index
>
> 之后新建一个实体，将这个实体插入到这个键所对应的==最前面==

这样，当我们要查询 key100 时，可以先通过哈希函数计算，得到 key100 的哈希值被映射到了桶 5 中。然后，我们再逐一比较桶 5 中串接的 key，直到查找到 key100。

如此一来，我们就能在链式哈希中找到所查的哈希项了。不过，链式哈希也存在局限性，那就是随着链表长度的增加，Hash 表在一个位置上查询哈希项的耗时就会增加，从而增加了 Hash 表的整体查询时间，这样也会导致 Hash 表的性能下降。

那么，有没有什么其他的方法可以减少对 Hash 表性能的影响呢？当然是有的，别急，等我介绍完整个字典的结构后，我就会和你聊一聊rehash操作。

### 1.2 哈希表

```c
typedef struct dictht {
    dictEntry **table;
    unsigned long size;
    unsigned long sizemask;
    unsigned long used;
} dictht;

```

- table:哈希表数组，由一系列实体所组成的hash数组，hash数组里面又对应着指向hashnode的指针
- size：哈希表大小
- sizemask：哈希表大小掩码，用于计算索引值
- used：该哈希表已有的节点

### 1.3. 字典

```c
typedef struct dict {
    // 类型特定函数
    dictType *type;
    // 私有数据
    void *privdata;
    // 哈希表
    dictht ht[2];
    long rehashidx; /* rehashing not in progress if rehashidx == -1 */
    unsigned long iterators; /* number of iterators currently running */
} dict;

```

type和privdata属性是针对不同键值对，为船舰多态字典而设置的。

- type属性是一个指向dictType结构的指针，每个dictType结构保存了一簇用于操作特定类型的键值对函数，Redis会为用途不同的字典设置不同类型的函数
- privdata属性则保存了需要传给哪些特定类型特定函数的可选参数

```c
typedef struct dictType {
    //计算哈希值的函数
    uint64_t (*hashFunction)(const void *key);
    //复制键的函数
    void *(*keyDup)(void *privdata, const void *key);
    //复制值的函数
    void *(*valDup)(void *privdata, const void *obj);
    //对比键的函数
    int (*keyCompare)(void *privdata, const void *key1, const void *key2);
    //销毁键的函数
    void (*keyDestructor)(void *privdata, void *key);
    //销毁值的函数
    void (*valDestructor)(void *privdata, void *obj);
} dictType;

```

举个简单的例子：

```c
#include <stdio.h>
#include<stdlib.h>
#include<string.h>
typedef struct name  name ;
typedef struct fun{
    void* (*getName)(name*);
    void*(*getAge)(name*);
}fun;

typedef struct name{
    fun* f;
    char  *who;
    unsigned age;
}name;
void * getName(name* n){
    return n->who;
}
void * getAge(name* n){
    return &(n->age);
}
int main(){
    name a;
    char *who="yangchaoyue";
    a.who=(char *)malloc(sizeof(char)*20);
    memset(a.who,0,20);
    memcpy(a.who,who,20);
    a.age=18;
    a.f=(fun*)malloc(sizeof (fun));
   printf("%p\n", getName);
   printf("%p\n", getAge);
    (a.f)->getName=getName;
    (a.f)->getAge=getAge;
   printf("%s\n",(char*)a.f->getName(&a));
   printf("%d\n",*((int*)(a.f->getAge(&a))));
   return 0;
}
```

dictType的实现思路和上述代码大致是相同的，采用函数指针的方式实现了多态，大家自行的体会体会。

ht属性是一个包含了两个项的哈希数组，数组中的每个项都是一个dictht哈希表，一般情况下，字典只使用ht[0]哈希表，ht[1]哈希表只会在对ht[0]哈希表进行rehash时使用。

rehashidx，它记录了rehash目前的进度，如果目前没有在rehash，那么它的值为-1。

#### 说说哈希函数

当要将一个新的键值对添加到字典里面时，程序需要现根据键值对的键计算出哈希值和索引值，然后再根据索引的值，将包含新键值对的哈希表节点放到哈希表数组指定的索引上面。

1. **单向性**：从哈希值不能反向推导原始数据（计算不可行），即从哈希输出无法倒推输入的原始数值。这是哈希函数安全性的基础。
2. **灵敏性**：==对输入数据敏感，哪怕只改了一个Bit，得到的哈希值也大不相同。==换言之，消息M的任何改变都会导致哈希值H（M）发生改变。
3. **易压易算**：Hash本质上是把一个大范围集合映射到另一个小范围集合。故输入值的个数必须与小范围相当或者更小，不然冲突就会很多。所以，哈希算法执行效率要高，散列结果要尽量均衡。
4. **抗碰撞性**：理想Hash函数是无碰撞的，但实际上很难做到这一点。有两种抗碰撞性：一种是弱抗碰撞性，即对于给定的消息，要发现另一个消息，满足在计算上是不可行的；另一种是强抗碰撞性，即对于任意一对不同的消息，使得在计算上也是不可行的。

#### **哈希函数的实际用途**

**Hash能把一个大范围映射到一个小范围，能对输入数据或文件进行校验，还可用于查找等。具体的：**

- 唯一标识或数据检验：能够对输入数据或文件进行校验，判断是否相同或是否被修改。如图片识别，可针对图像二进制流进行摘要后MD5，***得到的哈希值作为图片唯一标识***；如文件识别，服务器在接受文件上传时，对比两次传送文件的哈希值，若相同则无须再次上传（传统的奇偶校验和CRC校验一定程度上能检测并纠正数据传输中的信道误码，但没有抗数据篡改的能力）。
- 安全加密：对于敏感数据比如密码字段进行MD5或SHA加密传输。哈希算法还可以检验信息的拥有者是否真实。如，用保存密码的哈希值代替保存密码，基本可以杜绝泄密风险。
- 数字签名。由于非对称算法的运算速度较慢，所以在数字签名协议中，单向散列函数扮演了一个重要的角色。对Hash值，又称“数字摘要”进行数字签名，在统计上可以认为与对文件本身进行数字签名是等效的。
- 散列函数:是构造散列表的关键。它直接决定了散列冲突的概率和散列表的性质。不过相对哈希算法的其他方面应用，散列函数对散列冲突要求较低，出现冲突时可以通过开放寻址法或链表法解决冲突。对散列值是否能够反向解密要求也不高。反而更加关注的是散列的均匀性，即是否散列值均匀落入槽中以及散列函数执行的快慢也会影响散列表性能。所以散列函数一般比较简单，追求均匀和高效。
- 负载均衡：常用的负载均衡算法有很多，比如轮询、随机、加权轮询。如何实现一个会话粘滞的负载均衡算法呢？可以通过哈希算法，对客户端IP地址或会话SessionID计算哈希值，将取得的哈希值与服务器列表大小进行取模运算，最终得到应该被路由到的服务器编号。这样就可以把同一IP的客户端请求发到同一个后端服务器上。
- 数据分片：比如统计1T的日志文件中“搜索关键词”出现次数该如何解决？我们可以先对日志进行分片，然后采用多机处理，来提高处理速度。从搜索的日志中依次读取搜索关键词，并通过哈希函数计算哈希值，然后再跟n(机器数)取模，最终得到的值就是应该被分到的机器编号。这样相同哈希值的关键词就被分到同一台机器进行处理。每台机器分别计算关键词出现的次数，再进行合并就是最终结果。这也是MapReduce的基本思想。再比如图片识别应用中给每个图片的摘要信息取唯一标识然后构建散列表，如果图库中有大量图片，单机的hash表会过大，超过单机内存容量。这时也可以使用分片思想，准备n台机器，每台机器负责散列表的一部分数据。每次从图库取一个图片，计算唯一标识，然后与机器个数n求余取模，得到的值就是被分配到的机器编号，然后将这个唯一标识和图片路径发往对应机器构建散列表。当进行图片查找时，使用相同的哈希函数对图片摘要信息取唯一标识并对n求余取模操作后，得到的值k，就是当前图片所存储的机器编号，在该机器的散列表中查找该图片即可。实际上海量数据的处理问题，都可以借助这种数据分片思想，突破单机内存、CPU等资源限制。
- 分布式存储：一致性哈希算法解决缓存等分布式系统的扩容、缩容导致大量数据搬移难题。

#### 典型的哈希函数：

1. MD5（Message-Digest Algorithm 5）：MD5是一种广泛使用的哈希函数，可以将任意长度的数据转换为128位的哈希值。由于其较低的安全性和容易受到碰撞攻击的问题，现在已经逐渐被更安全的哈希算法所取代。
2. SHA（Secure Hash Algorithm）：SHA是一系列安全哈希算法的集合，SHA-1、SHA-2和SHA-3都是其中比较常用的。SHA-1可以将任意长度的数据转换为160位的哈希值，SHA-2可以生成256位或512位的哈希值，而SHA-3则可以生成任意长度的哈希值。
3. MurmurHash：MurmurHash是一种快速哈希函数，适用于哈希表、缓存等场景。它的特点是速度快，具有良好的分布特性和低碰撞率。
4. Jenkins Hash：Jenkins Hash是一种高效的哈希函数，适用于哈希表和散列数据结构。它的特点是速度快、均匀分布，并且具有良好的防碰撞性能。
5. xxHash：xxHash是一种快速哈希函数，适用于哈希表、缓存和数据完整性校验等场景。它的特点是速度非常快，具有良好的分布特性和低碰撞率。

哈希构造函数是一种用于构造哈希表、哈希树和其他哈希数据结构的算法。它的目的是通过将关键字映射到哈希值来实现高效的查找、插入和删除操作。

#### 典型的哈希构造函数：

以下是几种常见的哈希构造函数的方法：

1. 直接定址法（Direct Addressing）：直接定址法是一种最简单的哈希构造函数，它直接将关键字映射到哈希表的一个位置。当哈希表大小与关键字范围相同时，直接定址法具有最好的性能。
2. 数字分析法（Digit Analysis）：数字分析法是一种针对特定类型的数据（如电话号码、邮政编码等）的哈希构造函数。它将关键字中的数字分解为多个部分，然后将这些部分组合起来作为哈希值。
3. 平方取中法（Mid-Square）：平方取中法是一种将关键字平方后取中间几位作为哈希值的哈希构造函数。它适用于关键字的位数较少的情况，但容易产生哈希冲突。
4. 除留余数法（Division Method）：除留余数法是一种将关键字除以一个质数后取余数作为哈希值的哈希构造函数。它的实现简单，但在哈希表大小与关键字范围相同时容易产生哈希冲突。
5. 倍增法（Double Hashing）：倍增法是一种使用两个不同的哈希函数来构造哈希值的哈希构造函数。它适用于哈希表大小与关键字范围相等的情况，可以有效地避免哈希冲突。

需要注意的是，选择适合的哈希构造函数取决于具体的应用场景和数据类型，不同的哈希构造函数可能适用于不同的应用场景。在实际应用中，常常需要对哈希构造函数进行优化和改进，以获得更好的性能和更低的哈希冲突率。

#### 哈希函数和哈希构造的区别

哈希函数（hash function）是一种将任意大小的数据映射到固定大小的数据的函数，其输出通常称为哈希值或散列值。哈希函数通常用于安全加密、数据校验和、数据索引等领域。

哈希构造（hash construction）是指使用哈希函数来构建具有特定性质的数据结构，如哈希表、哈希树等。哈希构造的目的是利用哈希函数的特性，将数据分散到不同的位置，以便快速查找、插入和删除数据。哈希构造的实现需要选择合适的哈希函数，并设计合适的哈希冲突解决方案。

**因此，哈希函数和哈希构造是两个概念上的不同方面。哈希函数是一种数学函数，它可以将输入数据转换为固定长度的输出。而==哈希构造是使用哈希函数来构建数据结构的过程，以便于快速访问和操作数据==。**

我在用一张图描述一下hash表

![](D:\桌面\note\redis\redis设计与实现\images\hash1.png)

### 1.4. rehash操作

在哈希表中，当哈希表中的键值对数量增多时，可能会导致哈希冲突的增加，进而影响哈希表的性能。为了保持哈希表的性能，Redis中的哈希表使用了两个参数：load factor和rehash。

load factor指哈希表中键值对的数量与桶数的比值。当load factor较大时，哈希冲突会增多，影响性能；当load factor较小时，哈希表的空间利用率低下。通常情况下，load factor的值应该在0.5到2之间，这样可以保持良好的性能和空间利用率。

rehash是一种哈希表重新散列的操作。当哈希表中的键值对数量增加到一定阈值时，Redis会触发rehash操作，将原有的哈希表扩容为两倍大小，并重新计算所有键的哈希值，然后将键值对重新插入到新的哈希表中。在rehash期间，Redis会在新旧两个哈希表之间进行渐进式的迁移，每次从旧哈希表中迁移一部分键值对到新哈希表中，直到所有键值对都被迁移完毕。在这个过程中，Redis会保证所有的读操作都会在旧哈希表中进行，所有的写操作都会在新哈希表中进行，从而避免了并发读写带来的数据一致性问题。

rehash操作的时间复杂度为O(N)，其中N是键值对的数量。因此，在rehash期间，Redis可能会暂停服务，直到迁移完成。为了避免rehash过程过于频繁，Redis中的哈希表实现会预留一定的空间，当哈希表中的键值对数量接近预留空间时，Redis会主动触发rehash操作，避免哈希冲突的影响。

**Redis在对字典的哈希表执行rehash操作时，会按照以下步骤进行：**

1. 为新哈希表分配空间，空间大小为原有哈希表大小的两倍；
2. 将字典的rehashidx属性设为0，表示rehash操作正在进行中；
3. 将字典的ht[1]属性指向新哈希表，同时保留ht[0]属性指向原有哈希表；
4. 在字典中记录迁移进度，将dict.rehashidx属性设置为0；
5. 在迁移时，逐步将原有哈希表中的键值对移动到新哈希表中，直到所有键值对都被迁移完成；
6. 当所有键值对都迁移完成后，将ht[0]属性指向ht[1]，并释放原有哈希表的空间；
7. 将字典的rehashidx属性设为-1，表示rehash操作已完成。

需要注意的是，在rehash操作期间，==字典同时维护着原有哈希表和新哈希表==，为了避免并发读写带来的数据一致性问题，所有的读操作都会在原有哈希表中进行，所有的写操作都会在新哈希表中进行，直到所有键值对都被迁移完毕。==在这个过程中，Redis会保证读写操作的原子性和数据一致性==。

哈希表的扩展和收缩操作是为了保证哈希表的负载因子（load factor）在一定范围内，从而保证哈希表的查询、插入、删除等操作的效率。

#### rehash条件：

哈希表的负载因子指的是：**哈希表中已经使用的槽位数与总槽位数的比值**。当负载因子超过一定阈值时，哈希表会进行扩展操作，即增加槽位数，以==减少哈希冲突的概率==。当负载因子低于一定阈值时，哈希表会进行收缩操作，即减少槽位数，以==节省内存空间==。

哈希表的扩展和收缩条件如下：

1. **扩展条件：**

- 当哈希表中已使用的槽位数大于等于总槽位数（ht[0].used >= ht[0].size）且哈希表当前未处于rehash过程中；
- 或者当前正在进行rehash操作且已迁移的节点数大于等于总节点数的一半（ht[1].used >= ht[0].size / 2）。

1. **收缩条件：**

- 当哈希表中已使用的槽位数小于等于总槽位数的1/4（ht[0].used <= ht[0].size / 4）；
- 且哈希表当前未处于rehash过程中；
- 且哈希表的总槽位数大于初始槽位数（ht[0].size > DICT_HT_INITIAL_SIZE）。

需要注意的是，在进行扩展和收缩操作时，哈希表的大小增加或减少的步长不是固定的，而是动态调整的，以保证哈希表的负载因子在合适的范围内。

**哈希表的扩展和收缩条件与服务器的状态有关系，具体来说，如果 Redis 服务器处于忙碌状态，那么它可能会暂停哈希表的扩展和收缩操作，以避免对系统的性能造成过大的影响。**

Redis 的服务器状态分为以下四种：

1. **未初始化状态（UNINITIALIZED）**：当 Redis 服务器刚启动或数据集被清空时，处于该状态。
2. **运行中状态（RUNNING）**：Redis 服务器处于正常运行状态。
3. **加载中状态（LOADING）**：当 Redis 服务器在载入持久化数据集或执行 AOF 重写操作时，处于该状态。
4. **失败状态（ERROR）**：当 Redis 服务器出现严重错误或无法继续正常工作时，处于该状态。

**在 Redis 服务器处于未初始化或加载中状态时，哈希表的扩展和收缩操作都会被暂停**。==在 Redis 服务器处于运行中状态时，扩展和收缩操作会在满足一定条件的情况下进行==。而在 Redis 服务器处于失败状态时，哈希表的扩展和收缩操作都不会进行。

在运行中状态下，Redis 服务器还会根据当前时间和哈希表的使用情况，动态调整哈希表的大小和扩展和收缩操作的间隔时间，以达到更好的性能和稳定性。

在 Redis 服务器处于运行中状态时，哈希表的扩展和收缩操作会在满足以下条件的情况下进行：

1. 服务器没有在执行 BGSAVE 命令或 BGREWRITEAOF 命令：因为这两个命令都需要占用大量的 CPU 和内存资源，如果此时进行哈希表的扩展和收缩操作，会加重系统的负担。（这么说也并不完全正确，处于这种状态的时候，假如哈希表的负载因子超级大的时候，也会进行扩展与收缩操作）
2. 服务器当前没有在执行 Lua 脚本：Lua 脚本执行时会锁住整个 Redis 服务器，因此在这个时候进行哈希表的扩展和收缩操作会影响系统的性能。
3. 哈希表的负载因子（load factor）大于等于 1：负载因子指的是哈希表已使用节点数和哈希表大小之间的比率，如果小于等于0.1，说明位置十分富裕，需要收缩。
4. 连续多次出现哈希表操作导致哈希表的负载因子变化：连续多次执行哈希表操作，比如添加元素、删除元素等，可能会导致哈希表的负载因子发生变化，这个时候需要检查当前负载因子是否满足扩展或收缩的条件。

当满足以上条件时，Redis 服务器会根据当前哈希表的负载情况和负载因子的变化情况，动态地调整哈希表的大小和扩展和收缩操作的间隔时间，以达到更好的性能和稳定性。

#### 渐进式rehash

==哈希表扩展和收缩操作都需要对哈希表中的所有元素进行重新计算和重新散列，这个过程会消耗大量的 CPU 时间和内存带宽==。**如果 Redis 直接执行扩展和收缩操作，会导致 Redis 在操作期间无法响应客户端的请求，因此这种做法不太可行。**

为了解决这个问题，Redis 实现了渐进式 rehash 技术，它可以在不阻塞 Redis 服务器的情况下对哈希表进行扩展和收缩。通过渐进式 rehash 技术，Redis 可以将扩展和收缩操作分解成多个小步骤，每个小步骤只迁移或释放哈希表的一小部分元素，这样可以避免一次性对整个哈希表进行操作，从而使得 Redis 在操作期间可以继续响应客户端的请求。

此外，通过将扩展和收缩操作分解成多个小步骤，Redis 可以更加灵活地调整操作的进度和速度，使得操作过程对 Redis 服务器的影响更小。因此，渐进式 rehash 技术是 Redis 中非常重要的一个技术。

在执行渐进式 rehash 操作时，Redis 会为哈希表同时维护两个表：原哈希表（old table）和新哈希表（new table）。新哈希表的大小是原哈希表的两倍，但最初并不包含任何元素。

渐进式 rehash 分为两个阶段：

1. 迁移阶段（migration phase）：服务器将原哈希表中的所有键值对==逐渐地==迁移到新哈希表中。在迁移过程中，服务器会同时维护新旧哈希表两个表的索引。当客户端访问某个键时，服务器会**先在新哈希表中查找该键，如果没有找到，再在原哈希表中查找**。在迁移阶段中，服务器会逐步地将原哈希表的所有键值对迁移到新哈希表中，直到所有键值对都已经迁移完毕。
2.  渐进式收缩阶段（shrink phase）：服务器释放旧哈希表占用的内存空间。在这个阶段中，服务器会逐步地将原哈希表的大小缩小为新哈希表的大小，同时逐渐地释放原哈希表占用的内存空间，直到原哈希表全部释放完毕。

在渐进式 rehash 操作期间，服务器可以继续处理客户端的请求，不会阻塞整个 Redis 服务器。此外，由于渐进式 rehash 分为两个阶段，因此服务器也可以根据负载情况和其他因素，在不同的时间段内执行迁移和收缩操作。

下面我将用Redis设计与实践（黄健宏著）里面的五张图片为大家展示一下渐进式的rehash操作：

<img src="D:\桌面\note\redis\redis设计与实现\images\CBDFEA85F1BFCABA656B564142656F21.png" style="zoom: 25%;" />

<img src="D:\桌面\note\redis\redis设计与实现\images\12C6DF7975E3C0F86300CF1A74F0E706.png" style="zoom:25%;" />

<img src="D:\桌面\note\redis\redis设计与实现\images\B3206A8BB62CA6924C7AF1518E24F5C9.png" style="zoom:25%;" />

<img src="D:\桌面\note\redis\redis设计与实现\images\71A7E29B743EA65A159C1E99E2ACDAA0.png" style="zoom:25%;" />

<img src="D:\桌面\note\redis\redis设计与实现\images\BFB814D02F7B8548110446295DA66ABA.png" style="zoom:25%;" />

## 2. 再来看看全局哈希

```c
typedef struct redisDb {
    dict *dict;                 /* The keyspace for this DB */
    dict *expires;              /* Timeout of keys with a timeout set */
    dict *blocking_keys;        /* Keys with clients waiting for data (BLPOP)*/
    dict *ready_keys;           /* Blocked keys that received a PUSH */
    dict *watched_keys;         /* WATCHED keys for MULTI/EXEC CAS */
    int id;                     /* Database ID */
    long long avg_ttl;          /* Average TTL, just for stats */
    list *defrag_later;         /* List of key names to attempt to defrag one by one, gradually. */
} redisDb;
```
